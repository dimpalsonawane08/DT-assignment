{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimpalsonawane08/DT-assignment/blob/main/DT_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxWEnCoppqua",
        "outputId": "2c7eaae7-adfd-4471-883c-e7a6c5f924bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Type: Regression\n",
            "Target Variable: petal_width\n",
            "Regression Type: regression\n",
            "Partitioning Enabled: True\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def parse_target_config(json_data):\n",
        "    # Extracting the 'target' section from the JSON\n",
        "    target_config = json_data.get(\"target\", {})\n",
        "\n",
        "    # Reading the required information\n",
        "    prediction_type = target_config.get(\"prediction_type\", \"Not specified\")\n",
        "    target_variable = target_config.get(\"target\", \"Not specified\")\n",
        "    regression_type = target_config.get(\"type\", \"Not specified\")\n",
        "    partitioning = target_config.get(\"partitioning\", False)\n",
        "\n",
        "    # Printing the extracted information\n",
        "    print(f\"Prediction Type: {prediction_type}\")\n",
        "    print(f\"Target Variable: {target_variable}\")\n",
        "    print(f\"Regression Type: {regression_type}\")\n",
        "    print(f\"Partitioning Enabled: {partitioning}\")\n",
        "\n",
        "# Example JSON input\n",
        "json_input = \"\"\"\n",
        "{\n",
        "  \"target\": {\n",
        "    \"prediction_type\": \"Regression\",\n",
        "    \"target\": \"petal_width\",\n",
        "    \"type\": \"regression\",\n",
        "    \"partitioning\": true\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Parse the provided JSON\n",
        "json_data = json.loads(json_input)\n",
        "parse_target_config(json_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Your JSON input as a string\n",
        "json_input = \"\"\"\n",
        "{\n",
        "  \"feature_handling\": {\n",
        "    \"sepal_length\": {\n",
        "      \"feature_name\": \"sepal_length\",\n",
        "      \"is_selected\": true,\n",
        "      \"feature_variable_type\": \"numerical\",\n",
        "      \"feature_details\": {\n",
        "        \"numerical_handling\": \"Keep as regular numerical feature\",\n",
        "        \"rescaling\": \"No rescaling\",\n",
        "        \"make_derived_feats\": false,\n",
        "        \"missing_values\": \"Impute\",\n",
        "        \"impute_with\": \"Average of values\",\n",
        "        \"impute_value\": 0\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Parse the JSON input to get the configuration\n",
        "feature_config = json.loads(json_input)\n",
        "\n",
        "# Function to apply imputation based on the feature configuration\n",
        "def apply_imputation(df, feature_config):\n",
        "    for feature, config in feature_config[\"feature_handling\"].items():\n",
        "        if config[\"feature_details\"][\"missing_values\"] == \"Impute\":\n",
        "            if config[\"feature_details\"][\"impute_with\"] == \"Average of values\":\n",
        "                # Calculate the average without considering NaN values\n",
        "                avg_value = df[feature].mean()\n",
        "                # Fill NaN values with the calculated average\n",
        "                df[feature].fillna(avg_value, inplace=True)\n",
        "            # Extend this block to handle other imputation methods as needed\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('iris.csv')\n",
        "\n",
        "# Apply the imputation to the DataFrame based on the configuration\n",
        "apply_imputation(df, feature_config)\n",
        "\n",
        "# Display the DataFrame to verify the imputation\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOpTq_nZpusX",
        "outputId": "e9fc2830-af84-445b-a57c-5aad917fdd15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width         species\n",
            "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
            "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
            "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
            "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
            "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
            "..            ...          ...           ...          ...             ...\n",
            "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
            "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
            "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
            "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
            "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Assuming df is your DataFrame and target_variable is your target column's name\n",
        "def apply_feature_reduction(df, target_variable, config):\n",
        "    method = config[\"feature_reduction_method\"]\n",
        "    reduced_df = df.copy()\n",
        "\n",
        "    # No Reduction\n",
        "    if config[\"No Reduction\"][\"is_selected\"]:\n",
        "        # Assuming 'No Reduction' simply means limiting the number of features without any specific method\n",
        "        num_features = config[\"No Reduction\"][\"num_of_features_to_keep\"]\n",
        "        reduced_df = reduced_df.iloc[:, :num_features]\n",
        "\n",
        "    # Correlation with Target\n",
        "    elif config[\"Correlation with target\"][\"is_selected\"]:\n",
        "        num_features = config[\"Correlation with target\"][\"num_of_features_to_keep\"]\n",
        "        corr_scores = {col: pearsonr(df[col], df[target_variable])[0] for col in df.columns if df[col].dtype != 'object' and col != target_variable}\n",
        "        sorted_features = sorted(corr_scores, key=corr_scores.get, reverse=True)[:num_features]\n",
        "        reduced_df = df[sorted_features + [target_variable]]\n",
        "\n",
        "    # Tree-based\n",
        "    elif config[\"Tree-based\"][\"is_selected\"]:\n",
        "        num_features = config[\"Tree-based\"][\"num_of_features_to_keep\"]\n",
        "        clf = ExtraTreesClassifier(n_estimators=config[\"Tree-based\"][\"num_of_trees\"])\n",
        "        clf = clf.fit(df.drop(target_variable, axis=1), df[target_variable])\n",
        "        importances = clf.feature_importances_\n",
        "        indices = np.argsort(importances)[::-1][:num_features]\n",
        "        selected_features = df.columns[indices]\n",
        "        reduced_df = df[selected_features.tolist() + [target_variable]]\n",
        "\n",
        "    # PCA\n",
        "    elif config[\"Principal Component Analysis\"][\"is_selected\"]:\n",
        "        num_features = config[\"Principal Component Analysis\"][\"num_of_features_to_keep\"]\n",
        "        pca = PCA(n_components=num_features)\n",
        "        principalComponents = pca.fit_transform(df.drop(target_variable, axis=1))\n",
        "        reduced_df = pd.DataFrame(data = principalComponents, columns = [f'PC{i}' for i in range(1, num_features + 1)])\n",
        "        reduced_df[target_variable] = df[target_variable]\n",
        "\n",
        "    return reduced_df\n",
        "\n",
        "# Example usage:\n",
        "json_config = {\n",
        "  \"feature_reduction_method\": \"Correlation with target\",\n",
        "  \"No Reduction\": {\"is_selected\": True, \"num_of_features_to_keep\": 5},\n",
        "  \"Correlation with target\": {\"is_selected\": False, \"num_of_features_to_keep\": 8},\n",
        "  \"Tree-based\": {\"is_selected\": False, \"num_of_features_to_keep\": 0, \"depth_of_trees\": 0, \"num_of_trees\": 0},\n",
        "  \"Principal Component Analysis\": {\"is_selected\": False, \"num_of_features_to_keep\": 0},\n",
        "}\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('iris.csv')\n",
        "target_variable = 'YourTargetColumnNameHere'\n",
        "\n",
        "# Apply feature reduction\n",
        "reduced_df = apply_feature_reduction(df, target_variable, json_config)\n",
        "\n",
        "# Check the result\n",
        "print(reduced_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jsU9CZdpyWa",
        "outputId": "7926cc88-8775-4d30-d516-6dcc1c05521e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width      species\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "\n",
        "# Sample JSON configuration\n",
        "json_config = \"\"\"\n",
        "{\n",
        "  \"prediction_type\": \"Classification\",\n",
        "  \"models\": {\n",
        "    \"LogisticRegression\": {\n",
        "      \"model_name\": \"LogisticRegression\",\n",
        "      \"is_selected\": true,\n",
        "      \"parallelism\": 2,\n",
        "      \"min_iter\": 30,\n",
        "      \"max_iter\": 50,\n",
        "      \"min_regparam\": 0.5,\n",
        "      \"max_regparam\": 0.8,\n",
        "      \"min_elasticnet\": 0.5,\n",
        "      \"max_elasticnet\": 0.8\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Function to parse JSON and instantiate models\n",
        "def instantiate_model_from_json(json_str):\n",
        "    config = json.loads(json_str)\n",
        "    models = []\n",
        "\n",
        "    if config[\"prediction_type\"] == \"Classification\":\n",
        "        # For each model configuration\n",
        "        for model_name, model_config in config[\"models\"].items():\n",
        "            if model_config[\"is_selected\"]:\n",
        "                if model_name == \"LogisticRegression\":\n",
        "                    # Example: Instantiate logistic regression with averaged parameters\n",
        "                    # Adjust the instantiation as needed based on the parameters you want to use\n",
        "                    lr = LogisticRegression(\n",
        "                        max_iter=int((model_config[\"min_iter\"] + model_config[\"max_iter\"]) / 2),\n",
        "                        C=1.0 / ((model_config[\"min_regparam\"] + model_config[\"max_regparam\"]) / 2),  # Inverse of regularization strength\n",
        "                        # L1 ratio or other parameters related to elastic net can be set similarly\n",
        "                    )\n",
        "                    models.append(lr)\n",
        "                # Extend with elif blocks for other classification models as needed\n",
        "    elif config[\"prediction_type\"] == \"Regression\":\n",
        "        # Instantiate regression models similarly, for example:\n",
        "        pass  # Add logic for regression models here\n",
        "\n",
        "    return models\n",
        "\n",
        "# Example usage\n",
        "models = instantiate_model_from_json(json_config)\n",
        "for model in models:\n",
        "    print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbJLhNaAp21c",
        "outputId": "e5a4f154-8c48-4468-f32d-3d8f3e69eec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1.5384615384615383, max_iter=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X_train = np.random.rand(100, 10)\n",
        "y_train = np.random.rand(100)\n",
        "X_test = np.random.rand(50, 10)\n",
        "y_test=np.random.rand(50)\n",
        "\n",
        "# Define models and their parameter grids\n",
        "models = {\n",
        "    \"RandomForest\": (RandomForestRegressor(), {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20]}),\n",
        "    \"SVR\": (SVR(), {'kernel': ['linear', 'rbf'], 'C': [0.1, 1, 10]}),\n",
        "    \"LinearRegression\": (LinearRegression(), {'fit_intercept': [True, False]})\n",
        "}\n",
        "\n",
        "# TimeSeriesSplit cross-validation with overlap\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Iterate through each model, perform GridSearchCV, and fit the data\n",
        "for name, (model, param_grid) in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=tscv)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "    print(f\"Best score for {name}: {grid_search.best_score_}\")\n",
        "\n",
        "    # Predict using the best estimator obtained from GridSearchCV\n",
        "    predictions = grid_search.predict(X_test)\n",
        "    print(f\"Predictions for {name}: {predictions}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvEV9kUarx8l",
        "outputId": "e290abcd-f3b5-4e35-9bfe-390ad6bd184a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForest: {'max_depth': 20, 'n_estimators': 100}\n",
            "Best score for RandomForest: -0.24787319806312685\n",
            "Predictions for RandomForest: [0.37434416 0.48825906 0.56405843 0.56757672 0.52966837 0.53736262\n",
            " 0.66602753 0.45730846 0.42546368 0.55040461 0.62562038 0.57161722\n",
            " 0.53618962 0.57334666 0.50861142 0.4799144  0.55325484 0.63170151\n",
            " 0.5757476  0.71589786 0.59613496 0.46445903 0.44513736 0.48667665\n",
            " 0.62038129 0.4350278  0.60602586 0.46476412 0.53588438 0.45628066\n",
            " 0.50654763 0.58227094 0.57276554 0.4046303  0.53823337 0.44959865\n",
            " 0.52651779 0.54163115 0.3030529  0.46686691 0.56939142 0.50420507\n",
            " 0.42515199 0.42081531 0.60709961 0.40971738 0.50637711 0.50211444\n",
            " 0.62684909 0.48087206]\n",
            "Best parameters for SVR: {'C': 0.1, 'kernel': 'rbf'}\n",
            "Best score for SVR: -0.12244543438850788\n",
            "Predictions for SVR: [0.48082268 0.55028492 0.53211043 0.64947423 0.45755237 0.52620468\n",
            " 0.62951871 0.4937738  0.43818414 0.47230851 0.54348732 0.48716057\n",
            " 0.59986974 0.544194   0.45742082 0.61268169 0.55052971 0.60644731\n",
            " 0.48946449 0.59932698 0.57389332 0.51780863 0.47930381 0.57467898\n",
            " 0.56541445 0.50590711 0.59496899 0.49660011 0.55485846 0.53919755\n",
            " 0.44468376 0.43980211 0.60311566 0.45179016 0.53558124 0.46538148\n",
            " 0.43240754 0.50296107 0.37859061 0.41203282 0.4771542  0.51080833\n",
            " 0.54033745 0.37298121 0.63457146 0.47579992 0.52564532 0.5494126\n",
            " 0.63395085 0.60197009]\n",
            "Best parameters for LinearRegression: {'fit_intercept': False}\n",
            "Best score for LinearRegression: -0.7789359967289683\n",
            "Predictions for LinearRegression: [0.58211427 0.33630366 0.51477893 0.60442779 0.44121446 0.70725693\n",
            " 0.44497696 0.61181293 0.50478588 0.33960383 0.44464565 0.43666055\n",
            " 0.61202974 0.5151868  0.24363528 0.73820777 0.34492942 0.45834665\n",
            " 0.38597607 0.54074245 0.49338227 0.59094263 0.59417537 0.82147384\n",
            " 0.34647898 0.58816139 0.41990101 0.49573077 0.25527903 0.46329665\n",
            " 0.2508484  0.21253567 0.56319353 0.68097973 0.49765062 0.67795238\n",
            " 0.53187969 0.29147301 0.36449608 0.41996223 0.49057266 0.39645115\n",
            " 0.38060931 0.29760625 0.54599047 0.32017503 0.73428475 0.53393676\n",
            " 0.43603029 0.4955152 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Iterate through each model, perform GridSearchCV, and fit the data\n",
        "for name, (model, param_grid) in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=tscv)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "    print(f\"Best score for {name}: {grid_search.best_score_}\")\n",
        "\n",
        "    # Predict using the best estimator obtained from GridSearchCV\n",
        "    predictions = grid_search.predict(X_test)\n",
        "    print(f\"Predictions for {name}: {predictions}\")\n",
        "\n",
        "    # Evaluate model performance\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "\n",
        "    print(f\"Mean Absolute Error for {name}: {mae}\")\n",
        "    print(f\"Mean Squared Error for {name}: {mse}\")\n",
        "    print(f\"R-squared for {name}: {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBtA836FsFiq",
        "outputId": "5a454c9a-a688-4f1b-efd5-8c39254b057e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForest: {'max_depth': None, 'n_estimators': 100}\n",
            "Best score for RandomForest: -0.27311972506411764\n",
            "Predictions for RandomForest: [0.43379956 0.4864721  0.55717641 0.5336191  0.49911153 0.48976002\n",
            " 0.66603942 0.47489381 0.46398326 0.54742097 0.60171922 0.47988454\n",
            " 0.5157346  0.59215858 0.51119663 0.55925441 0.5845795  0.65007929\n",
            " 0.59490225 0.69228393 0.59363947 0.41378287 0.45750719 0.50166339\n",
            " 0.58651666 0.47645117 0.62276944 0.51579104 0.50664792 0.49071669\n",
            " 0.45644206 0.54820356 0.64005625 0.38983969 0.53887699 0.45342631\n",
            " 0.52214896 0.56665623 0.34407672 0.40990283 0.54337555 0.43571491\n",
            " 0.49253014 0.38125612 0.534983   0.41294354 0.51370574 0.49083115\n",
            " 0.66048227 0.44099258]\n",
            "Mean Absolute Error for RandomForest: 0.25258915108169994\n",
            "Mean Squared Error for RandomForest: 0.08572999562089607\n",
            "R-squared for RandomForest: -0.05444848174994377\n",
            "Best parameters for SVR: {'C': 0.1, 'kernel': 'rbf'}\n",
            "Best score for SVR: -0.12244543438850788\n",
            "Predictions for SVR: [0.48082268 0.55028492 0.53211043 0.64947423 0.45755237 0.52620468\n",
            " 0.62951871 0.4937738  0.43818414 0.47230851 0.54348732 0.48716057\n",
            " 0.59986974 0.544194   0.45742082 0.61268169 0.55052971 0.60644731\n",
            " 0.48946449 0.59932698 0.57389332 0.51780863 0.47930381 0.57467898\n",
            " 0.56541445 0.50590711 0.59496899 0.49660011 0.55485846 0.53919755\n",
            " 0.44468376 0.43980211 0.60311566 0.45179016 0.53558124 0.46538148\n",
            " 0.43240754 0.50296107 0.37859061 0.41203282 0.4771542  0.51080833\n",
            " 0.54033745 0.37298121 0.63457146 0.47579992 0.52564532 0.5494126\n",
            " 0.63395085 0.60197009]\n",
            "Mean Absolute Error for SVR: 0.2466228957106269\n",
            "Mean Squared Error for SVR: 0.08553146293953916\n",
            "R-squared for SVR: -0.05200660031838189\n",
            "Best parameters for LinearRegression: {'fit_intercept': False}\n",
            "Best score for LinearRegression: -0.7789359967289683\n",
            "Predictions for LinearRegression: [0.58211427 0.33630366 0.51477893 0.60442779 0.44121446 0.70725693\n",
            " 0.44497696 0.61181293 0.50478588 0.33960383 0.44464565 0.43666055\n",
            " 0.61202974 0.5151868  0.24363528 0.73820777 0.34492942 0.45834665\n",
            " 0.38597607 0.54074245 0.49338227 0.59094263 0.59417537 0.82147384\n",
            " 0.34647898 0.58816139 0.41990101 0.49573077 0.25527903 0.46329665\n",
            " 0.2508484  0.21253567 0.56319353 0.68097973 0.49765062 0.67795238\n",
            " 0.53187969 0.29147301 0.36449608 0.41996223 0.49057266 0.39645115\n",
            " 0.38060931 0.29760625 0.54599047 0.32017503 0.73428475 0.53393676\n",
            " 0.43603029 0.4955152 ]\n",
            "Mean Absolute Error for LinearRegression: 0.2490952072958677\n",
            "Mean Squared Error for LinearRegression: 0.094598587866045\n",
            "R-squared for LinearRegression: -0.16352901488690397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import json\n",
        "\n",
        "def feature_handling_pipeline():\n",
        "    # Define preprocessing steps for feature handling\n",
        "    preprocessing_steps = [('scaler', StandardScaler())]\n",
        "\n",
        "    # Create feature handling pipeline\n",
        "    feature_handling_pipe = Pipeline(steps=preprocessing_steps)\n",
        "    return feature_handling_pipe\n",
        "\n",
        "def feature_reduction_pipeline():\n",
        "    # Define preprocessing steps for feature reduction\n",
        "    preprocessing_steps = [('pca', PCA())]\n",
        "\n",
        "    # Create feature reduction pipeline\n",
        "    feature_reduction_pipe = Pipeline(steps=preprocessing_steps)\n",
        "    return feature_reduction_pipe\n",
        "\n",
        "def model_fit_pipeline(algo, param_grid, cv):\n",
        "    # Define model and its respective parameter grid\n",
        "    models = {\n",
        "        \"RandomForest\": (RandomForestRegressor(), param_grid),\n",
        "        \"SVR\": (SVR(), param_grid),\n",
        "        \"LinearRegression\": (LinearRegression(), param_grid)\n",
        "    }\n",
        "\n",
        "    # Create model fitting pipeline\n",
        "    model_pipe = Pipeline(steps=[\n",
        "        ('model', GridSearchCV(models[algo][0], models[algo][1], cv=cv))\n",
        "    ])\n",
        "    return model_pipe\n",
        "\n",
        "def parse_json_config(json_config):\n",
        "    # Parse JSON configuration\n",
        "    config = json.loads(json_config)\n",
        "\n",
        "    # Check if Grid Search is selected\n",
        "    if config.get(\"Grid Search\", {}).get(\"is selected\", False):\n",
        "        # Assuming only one algorithm is selected at a time\n",
        "        for algo, algo_config in config.items():\n",
        "            if algo != \"Grid Search\" and algo_config.get(\"is selected\", False):\n",
        "                return algo, algo_config\n",
        "\n",
        "    return None, None\n",
        "\n",
        "def execute_pipeline(json_config):\n",
        "    # Parse JSON configuration\n",
        "    algo, algo_config = parse_json_config(json_config)\n",
        "    if algo is None:\n",
        "        print(\"No algorithm selected for execution.\")\n",
        "        return\n",
        "\n",
        "    # Define pipelines for feature handling, feature reduction, and model fitting\n",
        "    feature_handling_pipe = feature_handling_pipeline()\n",
        "    feature_reduction_pipe = feature_reduction_pipeline()\n",
        "    model_pipe = model_fit_pipeline(algo, algo_config.get(\"param_grid\", {}), algo_config.get(\"cv\"))\n",
        "\n",
        "    # Combine pipelines using ColumnTransformer\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('feature_handling', feature_handling_pipe, slice(None)),  # Apply feature handling to all columns\n",
        "            ('feature_reduction', feature_reduction_pipe, slice(None))  # Apply feature reduction to all columns\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Combine preprocessor with model fitting pipeline\n",
        "    full_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', model_pipe)\n",
        "    ])\n",
        "\n",
        "    # Example data (replace with your actual data)\n",
        "    X_train = ...  # Your training features\n",
        "    y_train = ...  # Your training labels\n",
        "\n",
        "    # Fit the pipeline\n",
        "    full_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {algo}: {full_pipeline.named_steps['model'].best_params_}\")\n",
        "    print(f\"Best score for {algo}: {full_pipeline.named_steps['model'].best_score_}\")\n",
        "\n",
        "    # Example data for prediction (replace with your actual data)\n",
        "    X_test = ...  # Your test features\n",
        "    predictions = full_pipeline.predict(X_test)\n",
        "    print(f\"Predictions for {algo}: {predictions}\")\n",
        "\n",
        "# Example JSON configuration\n",
        "json_config = \"\"\"\n",
        "{\n",
        "    \"Grid Search\": {\n",
        "        \"is selected\": true,\n",
        "        \"RandomForest\": {\n",
        "            \"is_selected\": true,\n",
        "            \"param_grid\": {\n",
        "                \"n_estimators\": [10, 50, 100],\n",
        "                \"max_depth\": [None, 10, 20]\n",
        "            },\n",
        "            \"cv\": 5\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Execute the pipeline with the provided JSON configuration\n",
        "execute_pipeline(json_config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "HRAe9Uw5t2um",
        "outputId": "fd90096c-466f-4348-e9a7-d93d75ab8315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 9 column 31 (char 217)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d4ea875e5ac8>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# Execute the pipeline with the provided JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mexecute_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-d4ea875e5ac8>\u001b[0m in \u001b[0;36mexecute_pipeline\u001b[0;34m(json_config)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecute_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Parse JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_json_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No algorithm selected for execution.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-d4ea875e5ac8>\u001b[0m in \u001b[0;36mparse_json_config\u001b[0;34m(json_config)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_json_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Parse JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Check if Grid Search is selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 9 column 31 (char 217)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dYAH0jcyhcSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q5tQiB0ahaHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import json\n",
        "\n",
        "def feature_handling_pipeline():\n",
        "    # Define preprocessing steps for feature handling\n",
        "    preprocessing_steps = [('scaler', StandardScaler())]\n",
        "\n",
        "    # Create feature handling pipeline\n",
        "    feature_handling_pipe = Pipeline(steps=preprocessing_steps)\n",
        "    return feature_handling_pipe\n",
        "\n",
        "def feature_reduction_pipeline():\n",
        "    # Define preprocessing steps for feature reduction\n",
        "    preprocessing_steps = [('pca', PCA())]\n",
        "\n",
        "    # Create feature reduction pipeline\n",
        "    feature_reduction_pipe = Pipeline(steps=preprocessing_steps)\n",
        "    return feature_reduction_pipe\n",
        "\n",
        "def model_fit_pipeline(algo, param_grid, cv):\n",
        "    # Define model and its respective parameter grid\n",
        "    models = {\n",
        "        \"RandomForest\": (RandomForestRegressor(), param_grid),\n",
        "        \"SVR\": (SVR(), param_grid),\n",
        "        \"LinearRegression\": (LinearRegression(), param_grid)\n",
        "    }\n",
        "\n",
        "    # Create model fitting pipeline\n",
        "    model_pipe = Pipeline(steps=[\n",
        "        ('model', GridSearchCV(models[algo][0], models[algo][1], cv=cv))\n",
        "    ])\n",
        "    return model_pipe\n",
        "\n",
        "def parse_json_config(json_config):\n",
        "    # Parse JSON configuration\n",
        "    config = json.loads(json_config)\n",
        "\n",
        "    # Check if Grid Search is selected\n",
        "    if config.get(\"Grid Search\", {}).get(\"is_selected\", False):\n",
        "        # Assuming only one algorithm is selected at a time\n",
        "        for algo, algo_config in config.items():\n",
        "            if algo != \"Grid Search\" and algo_config.get(\"is_selected\", False):\n",
        "                return algo, algo_config\n",
        "\n",
        "    return None, None\n",
        "\n",
        "def execute_pipeline(json_config):\n",
        "    # Parse JSON configuration\n",
        "    algo, algo_config = parse_json_config(json_config)\n",
        "    if algo is None:\n",
        "        print(\"No algorithm selected for execution.\")\n",
        "        return\n",
        "\n",
        "    # Define pipelines for feature handling, feature reduction, and model fitting\n",
        "    feature_handling_pipe = feature_handling_pipeline()\n",
        "    feature_reduction_pipe = feature_reduction_pipeline()\n",
        "    model_pipe = model_fit_pipeline(algo, algo_config.get(\"param_grid\", {}), algo_config.get(\"cv\"))\n",
        "\n",
        "    # Combine pipelines using ColumnTransformer\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('feature_handling', feature_handling_pipe, slice(None)),  # Apply feature handling to all columns\n",
        "            ('feature_reduction', feature_reduction_pipe, slice(None))  # Apply feature reduction to all columns\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Combine preprocessor with model fitting pipeline\n",
        "    full_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', model_pipe)\n",
        "    ])\n",
        "\n",
        "    # Example data (replace with your actual data)\n",
        "    X_train = ...  # Your training features\n",
        "    y_train = ...  # Your training labels\n",
        "\n",
        "    # Fit the pipeline\n",
        "    full_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {algo}: {full_pipeline.named_steps['model'].best_params_}\")\n",
        "    print(f\"Best score for {algo}: {full_pipeline.named_steps['model'].best_score_}\")\n",
        "\n",
        "    # Example data for prediction (replace with your actual data)\n",
        "    X_test = ...  # Your test features\n",
        "    predictions = full_pipeline.predict(X_test)\n",
        "    print(f\"Predictions for {algo}: {predictions}\")\n",
        "\n",
        "# Corrected JSON configuration\n",
        "json_config = \"\"\"\n",
        "{\n",
        "    \"Grid Search\": {\n",
        "        \"is_selected\": true,\n",
        "        \"RandomForest\": {\n",
        "            \"is_selected\": true,\n",
        "            \"param_grid\": {\n",
        "                \"n_estimators\": [10, 50, 100],\n",
        "                \"max_depth\": [None, 10, 20]\n",
        "            },\n",
        "            \"cv\": 5\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Execute the pipeline with the provided JSON configuration\n",
        "execute_pipeline(json_config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "3FC_JKztucF6",
        "outputId": "34ade3a4-018d-4a44-c5e9-2f1cebc5d1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 9 column 31 (char 217)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-db800833f631>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# Execute the pipeline with the provided JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mexecute_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-db800833f631>\u001b[0m in \u001b[0;36mexecute_pipeline\u001b[0;34m(json_config)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecute_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Parse JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_json_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No algorithm selected for execution.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-db800833f631>\u001b[0m in \u001b[0;36mparse_json_config\u001b[0;34m(json_config)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_json_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Parse JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Check if Grid Search is selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 9 column 31 (char 217)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import json\n",
        "\n",
        "def feature_handling_pipeline():\n",
        "    # Define preprocessing steps for feature handling\n",
        "    preprocessing_steps = [('scaler', StandardScaler())]\n",
        "\n",
        "    # Create feature handling pipeline\n",
        "    feature_handling_pipe = Pipeline(steps=preprocessing_steps)\n",
        "    return feature_handling_pipe\n",
        "\n",
        "def feature_reduction_pipeline():\n",
        "    # Define preprocessing steps for feature reduction\n",
        "    preprocessing_steps = [('pca', PCA())]\n",
        "\n",
        "    # Create feature reduction pipeline\n",
        "    feature_reduction_pipe = Pipeline(steps=preprocessing_steps)\n",
        "    return feature_reduction_pipe\n",
        "\n",
        "def model_fit_pipeline(algo, param_grid, cv):\n",
        "    # Define model and its respective parameter grid\n",
        "    models = {\n",
        "        \"RandomForest\": (RandomForestRegressor(), param_grid),\n",
        "        \"SVR\": (SVR(), param_grid),\n",
        "        \"LinearRegression\": (LinearRegression(), param_grid)\n",
        "    }\n",
        "\n",
        "    # Create model fitting pipeline\n",
        "    model_pipe = Pipeline(steps=[\n",
        "        ('model', GridSearchCV(models[algo][0], models[algo][1], cv=cv))\n",
        "    ])\n",
        "    return model_pipe\n",
        "\n",
        "def parse_json_config(json_config):\n",
        "    # Parse JSON configuration\n",
        "    config = json.loads(json_config)\n",
        "\n",
        "    # Check if Grid Search is selected\n",
        "    if config.get(\"Grid Search\", {}).get(\"is_selected\", False):\n",
        "        # Assuming only one algorithm is selected at a time\n",
        "        for algo, algo_config in config.items():\n",
        "            if algo != \"Grid Search\" and algo_config.get(\"is_selected\", False):\n",
        "                return algo, algo_config\n",
        "\n",
        "    return None, None\n",
        "\n",
        "def execute_pipeline(json_config):\n",
        "    # Parse JSON configuration\n",
        "    algo, algo_config = parse_json_config(json_config)\n",
        "    if algo is None:\n",
        "        print(\"No algorithm selected for execution.\")\n",
        "        return\n",
        "\n",
        "    # Define pipelines for feature handling, feature reduction, and model fitting\n",
        "    feature_handling_pipe = feature_handling_pipeline()\n",
        "    feature_reduction_pipe = feature_reduction_pipeline()\n",
        "    model_pipe = model_fit_pipeline(algo, algo_config.get(\"param_grid\", {}), algo_config.get(\"cv\"))\n",
        "\n",
        "    # Combine pipelines using ColumnTransformer\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('feature_handling', feature_handling_pipe, slice(None)),  # Apply feature handling to all columns\n",
        "            ('feature_reduction', feature_reduction_pipe, slice(None))  # Apply feature reduction to all columns\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Combine preprocessor with model fitting pipeline\n",
        "    full_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', model_pipe)\n",
        "    ])\n",
        "\n",
        "    # Example data (replace with your actual data)\n",
        "    X_train = ...  # Your training features\n",
        "    y_train = ...  # Your training labels\n",
        "\n",
        "    # Fit the pipeline\n",
        "    full_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {algo}: {full_pipeline.named_steps['model'].best_params_}\")\n",
        "    print(f\"Best score for {algo}: {full_pipeline.named_steps['model'].best_score_}\")\n",
        "\n",
        "    # Example data for prediction (replace with your actual data)\n",
        "    X_test = ...  # Your test features\n",
        "    predictions = full_pipeline.predict(X_test)\n",
        "    print(f\"Predictions for {algo}: {predictions}\")\n",
        "\n",
        "# Corrected JSON configuration\n",
        "json_config = \"\"\"\n",
        "{\n",
        "    \"Grid Search\": {\n",
        "        \"is_selected\": true,\n",
        "        \"RandomForest\": {\n",
        "            \"is_selected\": true,\n",
        "            \"param_grid\": {\n",
        "                \"n_estimators\": [10, 50, 100],\n",
        "                \"max_depth\": [None, 10, 20]\n",
        "            },\n",
        "            \"cv\": 5\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Execute the pipeline with the provided JSON configuration\n",
        "execute_pipeline(json_config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "vvxvM6STvHbp",
        "outputId": "d761856e-c950-407b-9495-7900bc512a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 9 column 31 (char 217)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-db800833f631>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# Execute the pipeline with the provided JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mexecute_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-db800833f631>\u001b[0m in \u001b[0;36mexecute_pipeline\u001b[0;34m(json_config)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecute_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Parse JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_json_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No algorithm selected for execution.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-db800833f631>\u001b[0m in \u001b[0;36mparse_json_config\u001b[0;34m(json_config)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_json_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Parse JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Check if Grid Search is selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 9 column 31 (char 217)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import json\n",
        "\n",
        "def feature_handling_pipeline():\n",
        "    # Define preprocessing steps for feature handling\n",
        "    preprocessing_steps = [('scaler', StandardScaler())]\n",
        "\n",
        "    # Create feature handling pipeline\n",
        "    feature_handling_pipe = Pipeline(steps=preprocessing_steps)\n",
        "    return feature_handling_pipe\n",
        "\n",
        "def feature_reduction_pipeline():\n",
        "    # Define preprocessing steps for feature reduction\n",
        "    preprocessing_steps = [('pca', PCA())]\n",
        "\n",
        "    # Create feature reduction pipeline\n",
        "    feature_reduction_pipe = Pipeline(steps=preprocessing_steps)\n",
        "    return feature_reduction_pipe\n",
        "\n",
        "def model_fit_pipeline(algo, param_grid, cv):\n",
        "    # Define model and its respective parameter grid\n",
        "    models = {\n",
        "        \"RandomForest\": (RandomForestRegressor(), param_grid),\n",
        "        \"SVR\": (SVR(), param_grid),\n",
        "        \"LinearRegression\": (LinearRegression(), param_grid)\n",
        "    }\n",
        "\n",
        "    # Create model fitting pipeline\n",
        "    model_pipe = Pipeline(steps=[\n",
        "        ('model', GridSearchCV(models[algo][0], models[algo][1], cv=cv))\n",
        "    ])\n",
        "    return model_pipe\n",
        "\n",
        "def parse_json_config(json_config):\n",
        "    # Parse JSON configuration\n",
        "    config = json.loads(json_config)\n",
        "\n",
        "    # Check if Grid Search is selected\n",
        "    if config.get(\"Grid Search\", {}).get(\"is_selected\", False):\n",
        "        # Assuming only one algorithm is selected at a time\n",
        "        for algo, algo_config in config.items():\n",
        "            if algo != \"Grid Search\" and algo_config.get(\"is_selected\", False):\n",
        "                return algo, algo_config\n",
        "\n",
        "    return None, None\n",
        "\n",
        "def execute_pipeline(json_config):\n",
        "    # Parse JSON configuration\n",
        "    algo, algo_config = parse_json_config(json_config)\n",
        "    if algo is None:\n",
        "        print(\"No algorithm selected for execution.\")\n",
        "        return\n",
        "\n",
        "    # Define pipelines for feature handling, feature reduction, and model fitting\n",
        "    feature_handling_pipe = feature_handling_pipeline()\n",
        "    feature_reduction_pipe = feature_reduction_pipeline()\n",
        "    model_pipe = model_fit_pipeline(algo, algo_config.get(\"param_grid\", {}), algo_config.get(\"cv\"))\n",
        "\n",
        "    # Combine pipelines using ColumnTransformer\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('feature_handling', feature_handling_pipe, slice(None)),  # Apply feature handling to all columns\n",
        "            ('feature_reduction', feature_reduction_pipe, slice(None))  # Apply feature reduction to all columns\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Combine preprocessor with model fitting pipeline\n",
        "    full_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', model_pipe)\n",
        "    ])\n",
        "\n",
        "    # Example data (replace with your actual data)\n",
        "    X_train = ...  # Your training features\n",
        "    y_train = ...  # Your training labels\n",
        "\n",
        "    # Fit the pipeline\n",
        "    full_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {algo}: {full_pipeline.named_steps['model'].best_params_}\")\n",
        "    print(f\"Best score for {algo}: {full_pipeline.named_steps['model'].best_score_}\")\n",
        "\n",
        "    # Example data for prediction (replace with your actual data)\n",
        "    X_test = ...  # Your test features\n",
        "    predictions = full_pipeline.predict(X_test)\n",
        "    print(f\"Predictions for {algo}: {predictions}\")\n",
        "\n",
        "# Corrected JSON configuration\n",
        "json_config = \"\"\"\n",
        "{\n",
        "    \"Grid Search\": {\n",
        "        \"is_selected\": true,\n",
        "        \"RandomForest\": {\n",
        "            \"is_selected\": true,\n",
        "            \"param_grid\": {\n",
        "                \"n_estimators\": [10, 50, 100],\n",
        "                \"max_depth\": [None, 10, 20]\n",
        "            },\n",
        "            \"cv\": 5\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Execute the pipeline with the provided JSON configuration\n",
        "execute_pipeline(json_config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "gdtG2YsKviOo",
        "outputId": "37ace4a4-0f74-4787-a90e-473c3494d192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 9 column 31 (char 217)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-db800833f631>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# Execute the pipeline with the provided JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mexecute_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-db800833f631>\u001b[0m in \u001b[0;36mexecute_pipeline\u001b[0;34m(json_config)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecute_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Parse JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_json_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No algorithm selected for execution.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-db800833f631>\u001b[0m in \u001b[0;36mparse_json_config\u001b[0;34m(json_config)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_json_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Parse JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Check if Grid Search is selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 9 column 31 (char 217)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected JSON configuration\n",
        "json_config = \"\"\"\n",
        "{\n",
        "    \"Grid Search\": {\n",
        "        \"is_selected\": true,\n",
        "        \"RandomForest\": {\n",
        "            \"is_selected\": true,\n",
        "            \"param_grid\": {\n",
        "                \"n_estimators\": [10, 50, 100],\n",
        "                \"max_depth\": [None, 10, 20]\n",
        "            },\n",
        "            \"cv\": 5\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "0Kg5lvfgwks0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import json\n",
        "\n",
        "def feature_handling_pipeline():\n",
        "    # Define preprocessing steps for feature handling\n",
        "    preprocessing_steps = [('scaler', StandardScaler())]\n",
        "\n",
        "    # Create feature handling pipeline\n",
        "    feature_handling_pipe = Pipeline(steps=preprocessing_steps)\n",
        "    return feature_handling_pipe\n",
        "\n",
        "def feature_reduction_pipeline():\n",
        "    # Define preprocessing steps for feature reduction\n",
        "    preprocessing_steps = [('pca', PCA())]\n",
        "\n",
        "    # Create feature reduction pipeline\n",
        "    feature_reduction_pipe = Pipeline(steps=preprocessing_steps)\n",
        "    return feature_reduction_pipe\n",
        "\n",
        "def model_fit_pipeline(algo, param_grid, cv):\n",
        "    # Define model and its respective parameter grid\n",
        "    models = {\n",
        "        \"RandomForest\": (RandomForestRegressor(), param_grid),\n",
        "        \"SVR\": (SVR(), param_grid),\n",
        "        \"LinearRegression\": (LinearRegression(), param_grid)\n",
        "    }\n",
        "\n",
        "    # Create model fitting pipeline\n",
        "    model_pipe = Pipeline(steps=[\n",
        "        ('model', GridSearchCV(models[algo][0], models[algo][1], cv=cv))\n",
        "    ])\n",
        "    return model_pipe\n",
        "\n",
        "def parse_json_config(json_config):\n",
        "    # Parse JSON configuration\n",
        "    config = json.loads(json_config)\n",
        "\n",
        "    # Check if Grid Search is selected\n",
        "    if config.get(\"Grid Search\", {}).get(\"is_selected\", False):\n",
        "        # Assuming only one algorithm is selected at a time\n",
        "        for algo, algo_config in config.items():\n",
        "            if algo != \"Grid Search\" and algo_config.get(\"is_selected\", False):\n",
        "                return algo, algo_config\n",
        "\n",
        "    return None, None\n",
        "\n",
        "def execute_pipeline(json_config):\n",
        "    # Parse JSON configuration\n",
        "    algo, algo_config = parse_json_config(json_config)\n",
        "    if algo is None:\n",
        "        print(\"No algorithm selected for execution.\")\n",
        "        return\n",
        "\n",
        "    # Define pipelines for feature handling, feature reduction, and model fitting\n",
        "    feature_handling_pipe = feature_handling_pipeline()\n",
        "    feature_reduction_pipe = feature_reduction_pipeline()\n",
        "    model_pipe = model_fit_pipeline(algo, algo_config.get(\"param_grid\", {}), algo_config.get(\"cv\"))\n",
        "\n",
        "    # Combine pipelines using ColumnTransformer\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('feature_handling', feature_handling_pipe, slice(None)),  # Apply feature handling to all columns\n",
        "            ('feature_reduction', feature_reduction_pipe, slice(None))  # Apply feature reduction to all columns\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Combine preprocessor with model fitting pipeline\n",
        "    full_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', model_pipe)\n",
        "    ])\n",
        "\n",
        "    # Example data (replace with your actual data)\n",
        "    X_train = ...  # Your training features\n",
        "    y_train = ...  # Your training labels\n",
        "\n",
        "    # Fit the pipeline\n",
        "    full_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {algo}: {full_pipeline.named_steps['model'].best_params_}\")\n",
        "    print(f\"Best score for {algo}: {full_pipeline.named_steps['model'].best_score_}\")\n",
        "\n",
        "    # Example data for prediction (replace with your actual data)\n",
        "    X_test = ...  # Your test features\n",
        "    predictions = full_pipeline.predict(X_test)\n",
        "    print(f\"Predictions for {algo}: {predictions}\")\n",
        "\n",
        "# Corrected JSON configuration\n",
        "json_config = \"\"\"\n",
        "{\n",
        "    \"Grid Search\": {\n",
        "        \"is_selected\": true,\n",
        "        \"RandomForest\": {\n",
        "            \"is_selected\": true,\n",
        "            \"param_grid\": {\n",
        "                \"n_estimators\": [10, 50, 100],\n",
        "                \"max_depth\": [None, 10, 20]\n",
        "            },\n",
        "            \"cv\": 5\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Execute the pipeline with the provided JSON configuration\n",
        "execute_pipeline(json_config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "OSTo7DICwn1g",
        "outputId": "7ed4e3b4-2fc1-42fe-c8c5-5712c77d11cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 9 column 31 (char 217)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-db800833f631>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# Execute the pipeline with the provided JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mexecute_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-db800833f631>\u001b[0m in \u001b[0;36mexecute_pipeline\u001b[0;34m(json_config)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecute_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Parse JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_json_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No algorithm selected for execution.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-db800833f631>\u001b[0m in \u001b[0;36mparse_json_config\u001b[0;34m(json_config)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_json_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Parse JSON configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Check if Grid Search is selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 9 column 31 (char 217)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "878723vYwn4a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}